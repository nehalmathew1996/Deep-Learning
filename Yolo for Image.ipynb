{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04abadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69436a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "185bc3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'bicycle', 'car', 'motorbike', 'aeroplane']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=cv2.dnn.readNet('yolov3.weights','yolov3.cfg')\n",
    "classes=[]\n",
    "\n",
    "with open('coco.names','r') as f:\n",
    "    classes=f.read().splitlines()\n",
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3c4fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('images.jpeg')\n",
    "height,width,_=img.shape\n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccf96e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 448, 448)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1/255 -Scaling\n",
    "# (448,448) - Size of image\n",
    "# (0,0,0) - No Mean Subtraction\n",
    "# swapRB=True  -To convert BGR to RGB\n",
    "# crop = False - To avoid cropping\n",
    "\n",
    "# Blob is done because the model accepts a 4D input\n",
    "blob=cv2.dnn.blobFromImage(img,1/255,(448,448),(0,0,0),swapRB=True,crop=False)\n",
    "\n",
    "blob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39076059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what is in the blob\n",
    "for b in blob:\n",
    "    for n,img_blob in enumerate(b):\n",
    "        cv2.imshow(str(n),img_blob)\n",
    "\n",
    "        \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d21cd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "\n",
    "# Getting the name of the output layers\n",
    "#  To pass in the next function to get the output of these layers\n",
    "output_layers_names=net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Getting the output of the yolo network\n",
    "layerOutputs=net.forward(output_layers_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bb5bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1048585e-02, 3.6705948e-02, 4.0877530e-01, 1.0960779e-01,\n",
       "       2.4772417e-09, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerOutputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b43fadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store bounding boxes\n",
    "boxes=[]\n",
    "\n",
    "# To store confidence\n",
    "confidences=[]\n",
    "\n",
    "# To store classes_id\n",
    "class_ids=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e4127ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract above information from the Output of the yolo network (layerOutputs)\n",
    "\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        # Storing class probabilities\n",
    "        scores=detection[5:]\n",
    "        \n",
    "        # Storing Highest score location\n",
    "        class_id=np.argmax(scores)\n",
    "        \n",
    "        # Storing confidence/probabilty of detected object\n",
    "        confidence=scores[class_id]\n",
    "        \n",
    "        # Storing bounding box cordinares of objects with probabilty match of 50% and above\n",
    "        if (confidence > 0.75):\n",
    "            \n",
    "            # Multiplying with width to rescale to size of original image\n",
    "           \n",
    "            center_x=int(detection[0]*width)              \n",
    "            center_y=int(detection[1]*height)\n",
    "            w=int(detection[2]*width)\n",
    "            h=int(detection[3]*height)\n",
    "            \n",
    "            # Getting Position of upper left corner\n",
    "            x=int(center_x-w/2)\n",
    "            y=int(center_y-h/2)\n",
    "            \n",
    "            # Storing bounding box coordinates, confidences and class_id\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79b7ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "# Checking how many boxes where detected\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95eb9c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  2,  1, 14,  9, 39, 35, 33, 24, 22, 18, 36, 23,  4],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Surpressing Common detected boxes\n",
    "indexes=cv2.dnn.NMSBoxes(boxes,confidences,0.75,0.65)\n",
    "\n",
    "# Cheking ow many redundant boxes were there\n",
    "detected_obj=indexes.flatten()\n",
    "detected_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff939ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person 1.0\n",
      "person 1.0\n",
      "person 1.0\n",
      "person 0.96\n",
      "person 0.96\n",
      "mouse 0.93\n",
      "mouse 0.88\n",
      "cup 0.85\n",
      "laptop 0.85\n",
      "laptop 0.84\n",
      "tvmonitor 0.79\n",
      "pottedplant 0.78\n",
      "laptop 0.78\n",
      "person 0.77\n"
     ]
    }
   ],
   "source": [
    "font=cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# Assigning color for each detected object\n",
    "# 3 is the number of channels\n",
    "colors=np.random.uniform(0,255,size=(len(boxes),3))\n",
    "\n",
    "for i in detected_obj:\n",
    "    x,y,w,h=boxes[i]\n",
    "    label=str(classes[class_ids[i]])\n",
    "    confidence=str(round(confidences[i],2))\n",
    "    color=colors[i]\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "    cv2.putText(img,label+\" \"+confidence, (x,y+20),font,2,color,2)\n",
    "    print(label,confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d29ed8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b35d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
